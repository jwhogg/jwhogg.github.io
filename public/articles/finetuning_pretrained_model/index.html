<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width"><meta name="description" content="" />

<title>
    
    Fine-tuning a pre-trained model from HuggingFace | jwhogg
    
</title>







<link rel="stylesheet" href="/assets/combined.min.f69b4a5b91a9bc416804eda1f19d04210551b843d47318bf1913d7edce1504fb.css" media="all">



  </head>

  

  
  
  

  <body class="light">

    <div class="content">
      <header>
        

<div class="header">
    <h1 class="header-title">jwhogg</h1>

    <div class="flex">
        

        
    </div>

</div>
      </header>

      <main class="main">
        





<div >

  <div class="single-intro-container">

    

    <h1 class="single-title">Fine-tuning a pre-trained model from HuggingFace</h1>
    

    

    <p class="single-readtime">
      
      
      
      <time datetime="2024-05-24T13:29:04&#43;01:00">May 24, 2024</time>
      

      
    </p>

  </div>

  

  

  

  

  <div class="single-content">
    <p>We will be using a ðŸ¤— <a href="https://huggingface.co/">HuggingFace</a> model (<a href="https://huggingface.co/openai-community/gpt2-medium">GPT-2 Medium</a>)</p>
<h5 id="jupyter-notebookhttpsgithubcomjwhogggpt-2-fine-tuningblobmaingpt-220fine-tuning20cnndailymailipynb">ðŸ“™<strong><a href="https://github.com/jwhogg/GPT-2-Fine-Tuning/blob/main/GPT-2%20Fine-tuning%20CNNDailyMail.ipynb">Jupyter Notebook</a></strong></h5>
<h3 id="create-traintest-split-for-custom-dataset">Create train/test split for custom dataset</h3>
<p>(can use sklearn for this)</p>
<h3 id="get-the-model-tokeniser">Get the model tokeniser</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">from</span> transformers <span style="color:#ff79c6">import</span> AutoTokenizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#ff79c6">=</span> AutoTokenizer<span style="color:#ff79c6">.</span>from_pretrained(<span style="color:#f1fa8c">&#34;your-model-here&#34;</span>) <span style="color:#6272a4">#eg &#34;bert-base-cased&#34;</span>
</span></span></code></pre></div><h3 id="create-encodings-for-traintest-using-tokeniser">Create encodings for train/test using tokeniser</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">tokenize_function</span>(examples):
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> tokenizer(examples[<span style="color:#f1fa8c">&#34;text&#34;</span>], padding<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;max_length&#34;</span>, truncation<span style="color:#ff79c6">=</span><span style="color:#ff79c6">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenized_datasets <span style="color:#ff79c6">=</span> raw_datasets<span style="color:#ff79c6">.</span>map(tokenize_function, batched<span style="color:#ff79c6">=</span><span style="color:#ff79c6">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># where raw_datasets is a dict with train/dev/test</span>
</span></span></code></pre></div><ul>
<li>we need padding as the inputs must fit the models input even if they are too short</li>
</ul>
<h5 id="create-small-datasets-for-development">Create small datasets for development</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>small_train_dataset <span style="color:#ff79c6">=</span> tokenized_datasets[<span style="color:#f1fa8c">&#34;train&#34;</span>]<span style="color:#ff79c6">.</span>shuffle(seed<span style="color:#ff79c6">=</span><span style="color:#bd93f9">42</span>)<span style="color:#ff79c6">.</span>select(<span style="color:#8be9fd;font-style:italic">range</span>(<span style="color:#bd93f9">1000</span>)) 
</span></span><span style="display:flex;"><span>small_eval_dataset <span style="color:#ff79c6">=</span> tokenized_datasets[<span style="color:#f1fa8c">&#34;test&#34;</span>]<span style="color:#ff79c6">.</span>shuffle(seed<span style="color:#ff79c6">=</span><span style="color:#bd93f9">42</span>)<span style="color:#ff79c6">.</span>select(<span style="color:#8be9fd;font-style:italic">range</span>(<span style="color:#bd93f9">1000</span>)) 
</span></span><span style="display:flex;"><span>full_train_dataset <span style="color:#ff79c6">=</span> tokenized_datasets[<span style="color:#f1fa8c">&#34;train&#34;</span>]
</span></span><span style="display:flex;"><span>full_eval_dataset <span style="color:#ff79c6">=</span> tokenized_datasets[<span style="color:#f1fa8c">&#34;test&#34;</span>]
</span></span></code></pre></div><ul>
<li>use the full ones once you have all params figured out and want to do the final training</li>
</ul>
<h3 id="import-model">Import model</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">from</span> transformers <span style="color:#ff79c6">import</span> GPT2Tokenizer, GPT2Model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#ff79c6">=</span> GPT2Tokenizer<span style="color:#ff79c6">.</span>from_pretrained(<span style="color:#f1fa8c">&#39;gpt2-medium&#39;</span>)
</span></span><span style="display:flex;"><span>model <span style="color:#ff79c6">=</span> GPT2Model<span style="color:#ff79c6">.</span>from_pretrained(<span style="color:#f1fa8c">&#39;gpt2-medium&#39;</span>)
</span></span></code></pre></div><h3 id="training">Training</h3>
<ul>
<li><em>Transformers</em> has a <code>Trainer</code> class that can speed up training of models, and does a lot of the work for us</li>
<li><code>Trainer</code> is defined as a dict of arguments and a <code>compute_metrics</code> function, but first we need to define these:</li>
</ul>
<h5 id="training-args">Training args:</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">from</span> transformers <span style="color:#ff79c6">import</span> TrainingArguments
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>training_args <span style="color:#ff79c6">=</span> TrainingArguments(<span style="color:#f1fa8c">&#34;test_trainer&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#6272a4">#use just default args to start with</span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">#add arg: evaluation_strategy=&#34;epoch&#34; to report metrics every epoch</span>
</span></span></code></pre></div><h4 id="configure-training-metrics">Configure training metrics</h4>
<ul>
<li><em>Trainer</em> can take a <code>compute_metrics()</code> function, which takes predictions and labels (in a tuple), and returns a dict with metric names and values</li>
<li>we can use the <em>Datasets</em> library to get access to common metrics
<ul>
<li>&lsquo;accuracy&rsquo; is one of these</li>
</ul>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> numpy <span style="color:#ff79c6">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> datasets <span style="color:#ff79c6">import</span> load_metric
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>metric <span style="color:#ff79c6">=</span> load_metric(<span style="color:#f1fa8c">&#34;accuracy&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">compute_metrics</span>(eval_pred):
</span></span><span style="display:flex;"><span>    logits, labels <span style="color:#ff79c6">=</span> eval_pred <span style="color:#6272a4">#splitting tuple into the output logits and their labels</span>
</span></span><span style="display:flex;"><span>    predictions <span style="color:#ff79c6">=</span> np<span style="color:#ff79c6">.</span>argmax(logits, axis<span style="color:#ff79c6">=-</span><span style="color:#bd93f9">1</span>) <span style="color:#6272a4">#convert logits into predictions</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> metric<span style="color:#ff79c6">.</span>compute(predictions<span style="color:#ff79c6">=</span>predictions, references<span style="color:#ff79c6">=</span>labels) <span style="color:#6272a4">#calc predict accuracy</span>
</span></span></code></pre></div><h3 id="define-trainer">Define Trainer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">from</span> Transformers <span style="color:#ff79c6">import</span> Trainer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer <span style="color:#ff79c6">=</span> Trainer(
</span></span><span style="display:flex;"><span>    model<span style="color:#ff79c6">=</span>model,
</span></span><span style="display:flex;"><span>    args<span style="color:#ff79c6">=</span>training_args,
</span></span><span style="display:flex;"><span>    train_dataset<span style="color:#ff79c6">=</span>small_train_dataset,
</span></span><span style="display:flex;"><span>    eval_dataset<span style="color:#ff79c6">=</span>small_eval_dataset,
</span></span><span style="display:flex;"><span>    compute_metrics<span style="color:#ff79c6">=</span>compute_metrics,
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h3 id="train-and-evaluate">Train and Evaluate:</h3>
<pre tabindex="0"><code>trainer.train()
trainer.evaluate()
</code></pre><p>We are now done! the <a href="https://huggingface.co/docs/transformers/v4.15.0/en/main_classes/trainer#transformers.TrainingArguments">training args</a> or dataset can be tweaked to try to improve performance</p>
<p>Remember to <a href="https://discuss.huggingface.co/t/save-load-and-do-inference-with-fine-tuned-model/76291/2">save your model</a>!
<code>model.save_pretrained(&quot;path/to/model.pt&quot;)</code></p>

    
  </div>

  
  <div class="back-to-top">
    <a href="#top">
      back to top
    </a>
  </div>
  

</div>


      </main>
    </div>

    <footer>
      <p>Powered by
    <a href="https://gohugo.io/">Hugo</a>
    and
    <a href="https://github.com/tomfran/typo">tomfran/typo</a>
</p>


    </footer>

  </body>

  <script>

  function isAuto() {
    return document.body.classList.contains("auto");
  }

  function setTheme() {
    if (!isAuto()) {
      return
    }

    document.body.classList.remove("auto");
    let cls = "light";
    if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
      cls = "dark";
    }

    document.body.classList.add(cls);
  }

  function invertBody() {
    document.body.classList.toggle("dark");
    document.body.classList.toggle("light");
  }

  if (isAuto()) {
    window.matchMedia('(prefers-color-scheme: dark)').addListener(invertBody);
  }

  setTheme();

</script>

</html>