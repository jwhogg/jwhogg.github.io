<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width"><meta name="description" content="" />

<title>
    
    Fine-tuning a pre-trained model from HuggingFace | jwhogg
    
</title>







<link rel="stylesheet" href="/assets/combined.min.020f42c86d32ba80b53d3fc40ff0090ec5f74817ba9a0391ba123948ca68c7fc.css" media="all">





  </head>

  

  
  
  

  <body class="light">

    <div class="content">
      <header>
        

<div class="header">
    <h1 class="header-title">jwhogg</h1>
    

    <div class="flex">
        

        
        
        <p class="small ">
            <a href="/">
                /home
            </a>
        </p>

        <p>        </p>
        
        <p class="small ">
            <a href="/articles">
                /articles
            </a>
        </p>

        <p>        </p>
        
        <p class="small ">
            <a href="/portfolio">
                /portfolio
            </a>
        </p>

        <p>        </p>
        
        
        
        <div class="social-icons">
            <a href="www.linkedin.com/in/joel-w-hogg" target="_blank"
            rel="noopener noreferrer me"
            title="Linkedin">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path>
    <rect x="2" y="9" width="4" height="12"></rect>
    <circle cx="4" cy="4" r="2"></circle>
</svg>
            </a>
            <a href="https://github.com/jwhogg" target="_blank"
            rel="noopener noreferrer me"
            title="Github">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path
        d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22">
    </path>
</svg>
            </a>
            <a href="mailto:joelhogg45@gmail.com" target="_blank"
            rel="noopener noreferrer me"
            title="Email">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 21" fill="none" stroke="currentColor" stroke-width="2"
    stroke-linecap="round" stroke-linejoin="round">
    <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path>
    <polyline points="22,6 12,13 2,6"></polyline>
</svg>
            </a>
        </div>
    
    </div>

</div>
      </header>

      <main class="main">
        




<div class="breadcrumbs">
    
    <a href="/">Home</a>
    <span class="breadcrumbs-separator"> > </span>
    
    <a href="/articles/">Articles</a>
    <span class="breadcrumbs-separator"> > </span>
    
    <a class="breadcrumbs-current" href="/articles/finetuning_pretrained_model/">Fine-tuning a pre-trained model from HuggingFace</a>
</div>


<div >

  <div class="single-intro-container">

    

    <h1 class="single-title">Fine-tuning a pre-trained model from HuggingFace</h1>
    

    

    <p class="single-readtime">
      
      
      
      <time datetime="2024-05-24T13:29:04&#43;01:00">May 24, 2024</time>
      

      
    </p>

  </div>

  

  

  

  

  <div class="single-content">
    <p>We will be using a ðŸ¤— <a href="https://huggingface.co/">HuggingFace</a> model (<a href="https://huggingface.co/openai-community/gpt2-medium">GPT-2 Medium</a>)</p>
<p>ðŸ“™<strong><a href="https://github.com/jwhogg/GPT-2-Fine-Tuning/blob/main/GPT-2%20Fine-tuning%20CNNDailyMail.ipynb">Jupyter Notebook Link</a></strong></p>
<h3 id="create-traintest-split-for-custom-dataset">Create train/test split for custom dataset</h3>
<p>(can use sklearn for this)</p>
<h3 id="get-the-model-tokeniser">Get the model tokeniser</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">from</span> <span style="color:#666;font-weight:bold;font-style:italic">transformers</span> <span style="font-weight:bold;text-decoration:underline">import</span> AutoTokenizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer = AutoTokenizer.from_pretrained(<span style="color:#666;font-style:italic">&#34;your-model-here&#34;</span>) <span style="color:#888;font-style:italic">#eg &#34;bert-base-cased&#34;</span>
</span></span></code></pre></div><h3 id="create-encodings-for-traintest-using-tokeniser">Create encodings for train/test using tokeniser</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">def</span> <span style="color:#666;font-weight:bold;font-style:italic">tokenize_function</span>(examples):
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold;text-decoration:underline">return</span> tokenizer(examples[<span style="color:#666;font-style:italic">&#34;text&#34;</span>], padding=<span style="color:#666;font-style:italic">&#34;max_length&#34;</span>, truncation=<span style="font-weight:bold;text-decoration:underline">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenized_datasets = raw_datasets.map(tokenize_function, batched=<span style="font-weight:bold;text-decoration:underline">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#888;font-style:italic"># where raw_datasets is a dict with train/dev/test</span>
</span></span></code></pre></div><ul>
<li>we need padding as the inputs must fit the models input even if they are too short</li>
</ul>
<h5 id="create-small-datasets-for-development">Create small datasets for development</h5>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>small_train_dataset = tokenized_datasets[<span style="color:#666;font-style:italic">&#34;train&#34;</span>].shuffle(seed=42).select(<span style="font-weight:bold;font-style:italic">range</span>(1000)) 
</span></span><span style="display:flex;"><span>small_eval_dataset = tokenized_datasets[<span style="color:#666;font-style:italic">&#34;test&#34;</span>].shuffle(seed=42).select(<span style="font-weight:bold;font-style:italic">range</span>(1000)) 
</span></span><span style="display:flex;"><span>full_train_dataset = tokenized_datasets[<span style="color:#666;font-style:italic">&#34;train&#34;</span>]
</span></span><span style="display:flex;"><span>full_eval_dataset = tokenized_datasets[<span style="color:#666;font-style:italic">&#34;test&#34;</span>]
</span></span></code></pre></div><ul>
<li>use the full ones once you have all params figured out and want to do the final training</li>
</ul>
<h3 id="import-model">Import model</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">from</span> <span style="color:#666;font-weight:bold;font-style:italic">transformers</span> <span style="font-weight:bold;text-decoration:underline">import</span> GPT2Tokenizer, GPT2Model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer = GPT2Tokenizer.from_pretrained(<span style="color:#666;font-style:italic">&#39;gpt2-medium&#39;</span>)
</span></span><span style="display:flex;"><span>model = GPT2Model.from_pretrained(<span style="color:#666;font-style:italic">&#39;gpt2-medium&#39;</span>)
</span></span></code></pre></div><h3 id="training">Training</h3>
<ul>
<li><em>Transformers</em> has a <code>Trainer</code> class that can speed up training of models, and does a lot of the work for us</li>
<li><code>Trainer</code> is defined as a dict of arguments and a <code>compute_metrics</code> function, but first we need to define these:</li>
</ul>
<h5 id="training-args">Training args:</h5>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">from</span> <span style="color:#666;font-weight:bold;font-style:italic">transformers</span> <span style="font-weight:bold;text-decoration:underline">import</span> TrainingArguments
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>training_args = TrainingArguments(<span style="color:#666;font-style:italic">&#34;test_trainer&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#888;font-style:italic">#use just default args to start with</span>
</span></span><span style="display:flex;"><span><span style="color:#888;font-style:italic">#add arg: evaluation_strategy=&#34;epoch&#34; to report metrics every epoch</span>
</span></span></code></pre></div><h4 id="configure-training-metrics">Configure training metrics</h4>
<ul>
<li><em>Trainer</em> can take a <code>compute_metrics()</code> function, which takes predictions and labels (in a tuple), and returns a dict with metric names and values</li>
<li>we can use the <em>Datasets</em> library to get access to common metrics
<ul>
<li>&lsquo;accuracy&rsquo; is one of these</li>
</ul>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">import</span> <span style="color:#666;font-weight:bold;font-style:italic">numpy</span> <span style="font-weight:bold;text-decoration:underline">as</span> <span style="color:#666;font-weight:bold;font-style:italic">np</span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">from</span> <span style="color:#666;font-weight:bold;font-style:italic">datasets</span> <span style="font-weight:bold;text-decoration:underline">import</span> load_metric
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>metric = load_metric(<span style="color:#666;font-style:italic">&#34;accuracy&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">def</span> <span style="color:#666;font-weight:bold;font-style:italic">compute_metrics</span>(eval_pred):
</span></span><span style="display:flex;"><span>    logits, labels = eval_pred <span style="color:#888;font-style:italic">#splitting tuple into the output logits and their labels</span>
</span></span><span style="display:flex;"><span>    predictions = np.argmax(logits, axis=-1) <span style="color:#888;font-style:italic">#convert logits into predictions</span>
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold;text-decoration:underline">return</span> metric.compute(predictions=predictions, references=labels) <span style="color:#888;font-style:italic">#calc predict accuracy</span>
</span></span></code></pre></div><h3 id="define-trainer">Define Trainer</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="font-weight:bold;text-decoration:underline">from</span> <span style="color:#666;font-weight:bold;font-style:italic">Transformers</span> <span style="font-weight:bold;text-decoration:underline">import</span> Trainer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer = Trainer(
</span></span><span style="display:flex;"><span>    model=model,
</span></span><span style="display:flex;"><span>    args=training_args,
</span></span><span style="display:flex;"><span>    train_dataset=small_train_dataset,
</span></span><span style="display:flex;"><span>    eval_dataset=small_eval_dataset,
</span></span><span style="display:flex;"><span>    compute_metrics=compute_metrics,
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h3 id="train-and-evaluate">Train and Evaluate:</h3>
<pre tabindex="0"><code>trainer.train()
trainer.evaluate()
</code></pre><p>We are now done! the <a href="https://huggingface.co/docs/transformers/v4.15.0/en/main_classes/trainer#transformers.TrainingArguments">training args</a> or dataset can be tweaked to try to improve performance</p>
<p>Remember to <a href="https://discuss.huggingface.co/t/save-load-and-do-inference-with-fine-tuned-model/76291/2">save your model</a>!
<code>model.save_pretrained(&quot;path/to/model.pt&quot;)</code></p>

    
  </div>

  
  <div class="back-to-top">
    <a href="#top">
      back to top
    </a>
  </div>
  

</div>


      </main>
    </div>

    <footer>
      <p>Powered by
    <a href="https://gohugo.io/">Hugo</a>
    and
    <a href="https://github.com/tomfran/typo">tomfran/typo</a>
</p>


    </footer>

  </body>

  <script>

  function isAuto() {
    return document.body.classList.contains("auto");
  }

  function setTheme() {
    if (!isAuto()) {
      return
    }

    document.body.classList.remove("auto");
    let cls = "light";
    if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
      cls = "dark";
    }

    document.body.classList.add(cls);
  }

  function invertBody() {
    document.body.classList.toggle("dark");
    document.body.classList.toggle("light");
  }

  if (isAuto()) {
    window.matchMedia('(prefers-color-scheme: dark)').addListener(invertBody);
  }

  setTheme();

</script>

</html>